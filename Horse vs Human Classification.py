# -*- coding: utf-8 -*-
"""C2W4_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/version_3/C2/W4/assignment/C2W4_Assignment.ipynb
"""

import os
import zipfile
import urllib.request
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import img_to_array, load_img
from tensorflow.keras.applications.inception_v3 import InceptionV3

# Ensure pre-trained weights are downloaded
weights_url = "https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
weights_path = "/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"

if not os.path.exists(weights_path):
    print("Downloading InceptionV3 weights...")
    urllib.request.urlretrieve(weights_url, weights_path)
    print("Download complete.")

# Extract dataset
zipfile.ZipFile('./horse-or-human.zip', 'r').extractall('/tmp/training')
zipfile.ZipFile('./validation-horse-or-human.zip', 'r').extractall('/tmp/validation')

# Paths
train_dir = '/tmp/training'
validation_dir = '/tmp/validation'

# Data generators
def train_val_generators(TRAINING_DIR, VALIDATION_DIR):
    train_datagen = ImageDataGenerator(rescale=1.0/255,
                                       rotation_range=40,
                                       width_shift_range=0.2,
                                       height_shift_range=0.2,
                                       shear_range=0.2,
                                       zoom_range=0.2,
                                       horizontal_flip=True)

    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,
                                                        batch_size=32,
                                                        class_mode='binary',
                                                        target_size=(150, 150))

    validation_datagen = ImageDataGenerator(rescale=1.0/255)

    validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,
                                                                  batch_size=32,
                                                                  class_mode='binary',
                                                                  target_size=(150, 150))
    return train_generator, validation_generator

train_generator, validation_generator = train_val_generators(train_dir, validation_dir)

# Load pre-trained model
pre_trained_model = InceptionV3(input_shape=(150, 150, 3),
                                include_top=False,
                                weights=None)
pre_trained_model.load_weights(weights_path)

for layer in pre_trained_model.layers:
    layer.trainable = False

# Use output of 'mixed7' layer
last_output = pre_trained_model.get_layer('mixed7').output

# Custom callback
class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if logs.get('accuracy') > 0.999:
            print("\nReached 99.9% accuracy so cancelling training!")
            self.model.stop_training = True

# Final model
x = layers.Flatten()(last_output)
x = layers.Dense(1024, activation='relu')(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(1, activation='sigmoid')(x)

model = Model(inputs=pre_trained_model.input, outputs=x)
model.compile(optimizer=RMSprop(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train
callbacks = myCallback()
history = model.fit(train_generator,
                    validation_data=validation_generator,
                    epochs=100,
                    verbose=2,
                    callbacks=[callbacks])

# Plot accuracy
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()